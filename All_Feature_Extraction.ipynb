{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Extractions"
      ],
      "metadata": {
        "id": "daAcvOHHQRRi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qK-3fNfPS7W"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Specify the name of the uploaded file (ensure this is the exact name as it appears in Colab)\n",
        "image_name = 'fe1.png'  # Replace with the actual image file name\n",
        "\n",
        "# Load the image\n",
        "image = cv2.imread(image_name, cv2.IMREAD_COLOR)\n",
        "\n",
        "# Check if the image was loaded successfully\n",
        "if image is None:\n",
        "    print(f\"Error: Unable to load the image '{image_name}'. Please check if the file exists in the correct directory.\")\n",
        "else:\n",
        "    # Convert the image to grayscale\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Initialize the MSER detector with a higher delta for fewer regions\n",
        "    mser = cv2.MSER_create(delta=20)\n",
        "\n",
        "    # Detect MSER regions\n",
        "    regions, _ = mser.detectRegions(gray_image)\n",
        "\n",
        "    # Create a copy of the original image to draw the regions on\n",
        "    image_with_regions = image.copy()\n",
        "\n",
        "    # Draw MSER regions on the image\n",
        "    for region in regions:\n",
        "        x, y, w, h = cv2.boundingRect(region)\n",
        "        cv2.rectangle(image_with_regions, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "    # Display the image with MSER regions highlighted\n",
        "    cv2_imshow(image_with_regions)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def load_image(image_path, gray=True):\n",
        "    \"\"\" Load the input aerial image. \"\"\"\n",
        "    img = cv2.imread(image_path)\n",
        "    if gray:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    return img\n",
        "\n",
        "def extract_brief_features(image, max_keypoints=500):\n",
        "    \"\"\"\n",
        "    Extract BRIEF descriptors from aerial image.\n",
        "    :param image: Grayscale input image.\n",
        "    :param max_keypoints: Max number of keypoints to detect using STAR detector.\n",
        "    :return: Keypoints and BRIEF descriptors.\n",
        "    \"\"\"\n",
        "    # Detect keypoints using FAST or STAR\n",
        "    keypoint_detector = cv2.xfeatures2d.StarDetector_create()\n",
        "    keypoints = keypoint_detector.detect(image)\n",
        "\n",
        "    # Sort and keep the top N keypoints (for consistency)\n",
        "    keypoints = sorted(keypoints, key=lambda x: -x.response)[:max_keypoints]\n",
        "\n",
        "    # Apply BRIEF\n",
        "    brief_extractor = cv2.xfeatures2d.BriefDescriptorExtractor_create()\n",
        "    keypoints, descriptors = brief_extractor.compute(image, keypoints)\n",
        "\n",
        "    return keypoints, descriptors\n",
        "\n",
        "def visualize_keypoints(image, keypoints, title=\"BRIEF Keypoints\"):\n",
        "    \"\"\" Visualize detected keypoints on the image. \"\"\"\n",
        "    img_with_kp = cv2.drawKeypoints(image, keypoints, None, color=(0, 255, 0),\n",
        "                                    flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.imshow(img_with_kp, cmap='gray')\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def brief_descriptor_to_binary(descriptor):\n",
        "    \"\"\"\n",
        "    Convert a BRIEF descriptor to a binary string representation (as per Equation 10).\n",
        "    \"\"\"\n",
        "    return ''.join(['1' if val else '0' for val in descriptor.astype(bool)])\n",
        "\n",
        "def show_sample_descriptor(descriptors, index=0):\n",
        "    \"\"\"\n",
        "    Print the binary descriptor of a selected keypoint.\n",
        "    \"\"\"\n",
        "    if descriptors is not None and index < len(descriptors):\n",
        "        binary_string = brief_descriptor_to_binary(descriptors[index])\n",
        "        print(f\"Binary BRIEF descriptor for keypoint {index}:\\n{binary_string}\")\n",
        "    else:\n",
        "        print(\"Descriptor not available.\")\n",
        "\n",
        "# ========================= RUNNING SECTION =========================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    image_path = \"aerial_image.jpg\"  # Replace with your actual path\n",
        "\n",
        "    # Load image\n",
        "    gray_img = load_image(image_path)\n",
        "\n",
        "    # Extract BRIEF features\n",
        "    keypoints, descriptors = extract_brief_features(gray_img)\n",
        "\n",
        "    # Visualize the keypoints\n",
        "    visualize_keypoints(gray_img, keypoints)\n",
        "\n",
        "    # Show sample descriptor\n",
        "    show_sample_descriptor(descriptors, index=0)\n"
      ],
      "metadata": {
        "id": "AP6FQTdpQfC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def affine_transform(image, angle, scale=1.0):\n",
        "    \"\"\"\n",
        "    Apply affine transformation to the image.\n",
        "\n",
        "    Args:\n",
        "    image (ndarray): Input image.\n",
        "    angle (float): Angle for rotation.\n",
        "    scale (float): Scaling factor.\n",
        "\n",
        "    Returns:\n",
        "    transformed_image: Affine-transformed image.\n",
        "    \"\"\"\n",
        "    rows, cols = image.shape[:2]\n",
        "\n",
        "    # Create rotation matrix\n",
        "    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, scale)\n",
        "\n",
        "    # Apply affine transformation\n",
        "    transformed_image = cv2.warpAffine(image, M, (cols, rows))\n",
        "\n",
        "    return transformed_image\n",
        "\n",
        "def extract_sift_features(image):\n",
        "    \"\"\"\n",
        "    Function to extract SIFT features from the image.\n",
        "\n",
        "    Args:\n",
        "    image (ndarray): Input image.\n",
        "\n",
        "    Returns:\n",
        "    keypoints, descriptors: Detected keypoints and computed descriptors.\n",
        "    \"\"\"\n",
        "    # Convert image to grayscale\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Initialize SIFT detector\n",
        "    sift = cv2.SIFT_create()\n",
        "\n",
        "    # Detect keypoints and compute descriptors\n",
        "    keypoints, descriptors = sift.detectAndCompute(gray_image, None)\n",
        "\n",
        "    return keypoints, descriptors\n",
        "\n",
        "def draw_keypoints(image, keypoints, max_keypoints=500):\n",
        "    \"\"\"\n",
        "    Draw keypoints on the image, showing only the strongest ones.\n",
        "\n",
        "    Args:\n",
        "    image (ndarray): Input image.\n",
        "    keypoints (list): Detected keypoints.\n",
        "    max_keypoints (int): Maximum number of strongest keypoints to draw.\n",
        "\n",
        "    Returns:\n",
        "    Image with keypoints drawn.\n",
        "    \"\"\"\n",
        "    # Sort keypoints by their response (strength) and keep the top N keypoints\n",
        "    keypoints = sorted(keypoints, key=lambda x: x.response, reverse=True)[:max_keypoints]\n",
        "\n",
        "    # Draw keypoints with smaller circles for cleaner visualization\n",
        "    output_image = cv2.drawKeypoints(image, keypoints, None,\n",
        "                                     flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS,\n",
        "                                     color=(10, 0, 255))\n",
        "    return output_image\n",
        "\n",
        "# Load your aerial image (replace with your own image name)\n",
        "image = cv2.imread('fe1.png')\n",
        "\n",
        "if image is None:\n",
        "    print(\"Error: Unable to load the image.\")\n",
        "else:\n",
        "    # Preprocess the image (optional)\n",
        "    # Apply Gaussian blur to reduce noise\n",
        "    image = cv2.GaussianBlur(image, (5, 5), 0)\n",
        "\n",
        "    # List of angles to simulate different affine transformations\n",
        "    angles = [0, 15, 30, 45, 60, 75, 90]\n",
        "\n",
        "    all_keypoints = []\n",
        "    all_descriptors = []\n",
        "\n",
        "    # Apply different affine transformations\n",
        "    for angle in angles:\n",
        "        transformed_image = affine_transform(image, angle)\n",
        "\n",
        "        # Extract SIFT features from the transformed image\n",
        "        keypoints, descriptors = extract_sift_features(transformed_image)\n",
        "\n",
        "        all_keypoints.extend(keypoints)\n",
        "        if descriptors is not None:\n",
        "            all_descriptors.append(descriptors)\n",
        "\n",
        "    # Combine all descriptors\n",
        "    if all_descriptors:\n",
        "        all_descriptors = np.vstack(all_descriptors)\n",
        "\n",
        "    # Draw only the strongest keypoints on the original image\n",
        "    image_with_keypoints = draw_keypoints(image, all_keypoints, max_keypoints=5000)\n",
        "\n",
        "    # Display the result\n",
        "    cv2_imshow(image_with_keypoints)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "    print(f\"Total number of keypoints detected (before filtering): {len(all_keypoints)}\")\n"
      ],
      "metadata": {
        "id": "I1_Uux94Q4Td"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}